{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC MODELLING\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "\n",
    "NMF (Non-negative Matrix Factorization): \n",
    "A->W+H avec \n",
    "A=articles by words, original\n",
    "H=Article by topics, topics found\n",
    "W=topics by words, weight of these topics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "NMF is more scalable than LDA, but LDA more frequently used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/evan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text cleaning\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "punc=string.punctuation\n",
    "nltk.download('stopwords')\n",
    "stops=set(stopwords.words('english'))\n",
    "#print(stops)\n",
    "\n",
    "\n",
    "def process_text(t):\n",
    "    t=casual_tokenize(t)\n",
    "    \n",
    "    t=[e.lower() for e in t]\n",
    "    \n",
    "    t=[re.sub('[0-9]+', '',e) for e in t]\n",
    "    \n",
    "    t=[contractions.fix(e) for e in t]\n",
    "    \n",
    "    t=[SnowballStemmer('english').stem(e) for e in t]\n",
    "    t=[w for w in t if w not in punc]\n",
    "    t=[w for w in t if w not in stops]\n",
    "    t=[e for e in t if len(e)>1]\n",
    "    t=[e for e in t if ' ' not in e]\n",
    "    \n",
    "    return t\n",
    "\n",
    "\n",
    "#text = 'In the new system “Canton becomes Guangzhou and Tientsin becomes Tianjin.” Most importantly, the newspaper would now refer to the country’s capital as Beijing, not Peking. This was a step too far for some American publications. In an article on Pinyin around this time, the Chicago Tribune said that while it would be adopting the system for most Chinese words, some names had “become so ingrained'\n",
    "#print(text)\n",
    "#text_cleaned=process_text(text)\n",
    "#print(text_cleaned)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52fd7cfe315652c26f116941759022c1154f5724bf85b7c7e9d121c272da0755"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
