{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques utilisées\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "from lime import lime_tabular\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/evan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# On rend analysable les textes : on passe les caractères en minuscule, on enlève la ponctuation etc.\n",
    "\n",
    "def preprocessing(fake=pd.read_csv(\"True.csv\"),true=pd.read_csv(\"True.csv\")):\n",
    "    fake['target'] = 'fake'\n",
    "    true['target'] = 'true'\n",
    "    data = pd.concat([fake, true]).reset_index(drop = True)\n",
    "    data.drop([\"date\"],axis=1,inplace=True)\n",
    "    data.drop([\"title\"],axis=1,inplace=True)\n",
    "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "\n",
    "    def punctuation_removal(text):\n",
    "        all_list = [char for char in text if char not in string.punctuation]\n",
    "        clean_str = ''.join(all_list)\n",
    "        return clean_str\n",
    "\n",
    "    data['text'] = data['text'].apply(punctuation_removal)\n",
    "    nltk.download('stopwords')\n",
    "    stop = stopwords.words('english')\n",
    "    data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    #print('data lenght = ',len(data))\n",
    "    #print('lenfake = ',lenfake)\n",
    "    #print('lentrue = ',lentrue)\n",
    "   \n",
    "    return(data)\n",
    "\n",
    "data=preprocessing()\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42834\n",
      " b =  [8760, 12145, 34798, 33861, 39108]\n",
      " a =  [0, 4, 2, 3, 1]\n",
      "data =                                                      text       subject target\n",
      "0      washington reuters head conservative republica...  politicsNews   fake\n",
      "1      washington reuters transgender people allowed ...  politicsNews   fake\n",
      "2      washington reuters special counsel investigati...  politicsNews   fake\n",
      "3      washington reuters trump campaign adviser geor...  politicsNews   fake\n",
      "4      seattlewashington reuters president donald tru...  politicsNews   fake\n",
      "...                                                  ...           ...    ...\n",
      "42829  brussels reuters nato allies tuesday welcomed ...     worldnews   true\n",
      "42830  london reuters lexisnexis provider legal regul...     worldnews   true\n",
      "42831  minsk reuters shadow disused sovietera factori...     worldnews   true\n",
      "42832  moscow reuters vatican secretary state cardina...     worldnews   true\n",
      "42833  jakarta reuters indonesia buy 11 sukhoi fighte...     worldnews   true\n",
      "\n",
      "[42834 rows x 3 columns]\n",
      "y_test =  33861    true\n",
      "4        fake\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "    # Selection de la taille des échantillons\n",
    "\n",
    "    nbfake=5\n",
    "    nbtrue=5\n",
    "    lenfake=5\n",
    "    lentrue=5\n",
    "\n",
    "    '''\n",
    "    if nbfake>=(lenfake-1):\n",
    "        print('Not enough fake news in dataset')\n",
    "    if nbtrue>=(lentrue-1):\n",
    "        print('Not enough true news in dataset')\n",
    "    '''\n",
    "\n",
    "    print(len(data))\n",
    "    a=random.sample(range(0, lenfake), nbfake)\n",
    "    b=random.sample(range(lenfake+1, len(data)-1), nbtrue)\n",
    "    #print(b)\n",
    "    print(' b = ',b)\n",
    "    d=data.iloc[a][:]\n",
    "    print(\" a = \", a)\n",
    "\n",
    "    print(\"data = \",data)\n",
    "    e=data.iloc[b][:]\n",
    "    \n",
    "    data2=pd.concat([d,e], axis=0)\n",
    "\n",
    "# Formation des echantillons d'entrainement et de test\n",
    "    X_train,X_test,y_train,y_test = train_test_split(data2['text'],data2.target,test_size=0.2,random_state=42)\n",
    "\n",
    "print('y_test = ',y_test)\n",
    "\n",
    "\n",
    "#data2=dataproc(preprocessing(),nbfake,nbtrue)\n",
    "#print(data2[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def subjects(data):\\n    print(data.groupby([\\'subject\\'])[\\'text\\'].count())\\n    data.groupby([\\'subject\\'])[\\'text\\'].count().plot(kind=\"bar\")\\n    plt.show()\\n\\nsubjects(dataproc(data2,13,14))'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def subjects(data):\n",
    "    print(data.groupby(['subject'])['text'].count())\n",
    "    data.groupby(['subject'])['text'].count().plot(kind=\"bar\")\n",
    "    plt.show()\n",
    "\n",
    "subjects(dataproc(data2,13,14))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de vectorisation des textes\n",
    "\n",
    "def vecto(X_train,X_test):\n",
    "    \n",
    "    X_t=pd.concat([X_train,X_test])\n",
    "    #print('X_t = ',X_t.shape)\n",
    "    ltotal=len(X_t)\n",
    "    #print(X_t)\n",
    "    vectorizer = TfidfVectorizer(lowercase=False)\n",
    "    v = vectorizer.fit_transform(X_t)\n",
    "\n",
    "    features=vectorizer.get_feature_names_out()\n",
    "    ltrain=len(X_train)\n",
    "    vtrain=v[0:ltrain][:]\n",
    "    vtest=v[ltrain:][:]\n",
    "    vtrain=scipy.sparse.csr_matrix.toarray(vtrain)\n",
    "    vtest=scipy.sparse.csr_matrix.toarray(vtest)\n",
    "\n",
    "    return(vtrain,vtest,vectorizer,features)\n",
    "    \n",
    "\n",
    "#print(vecto(data2[0],data2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function classifLogReg at 0x7f91391c9430>\n"
     ]
    }
   ],
   "source": [
    "# Fonction de test des performances de la classification par Regression Logistique\n",
    "\n",
    "def classifLogReg(vtrain,vtest,y_train,y_test):\n",
    "    mo=LogisticRegression()\n",
    "    mo.fit(vtrain,y_train)\n",
    "    m=mo.predict(vtest)\n",
    "    m=np.array(m)\n",
    "    y_test=np.array(y_test)\n",
    "    #print(y_test)\n",
    "    #print(m)\n",
    "\n",
    "    #print(\"accuracy: {}%\".format(round(accuracy_score(y_test, m)*100,2)))\n",
    "    return(round(accuracy_score(y_test, m)*100,2))\n",
    "print(classifLogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction classifiant les news en utilisant le modèle Bayesien naïf a laquelle on a branché l'outil d'explicabilité Lime. Retourne à partir des données les résultats de classification,\n",
    "# sa performance et les mots constituant les news ayant eu la plus grande incidence sur le resultat de la classification.\n",
    "\n",
    "def classifNaiveBayes(vtrain,y_train,vectorizer,X_test,features):\n",
    "    mo=MultinomialNB()\n",
    "    mo.fit(vtrain,y_train)\n",
    "\n",
    "    i=X_test.index\n",
    "    j=i[1]\n",
    "\n",
    "    o=pd.Series(X_test[j])\n",
    "    o=vectorizer.transform(o)\n",
    "    o=scipy.sparse.csr_matrix.toarray(o)\n",
    "    o=o[0]\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(vtrain,mode=\"classification\",categorical_features=features,feature_names=features)\n",
    "    exp=explainer.explain_instance(data_row=o,predict_fn=mo.predict_proba, num_features=20) #labels=features\n",
    "    exp.as_pyplot_figure()\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.tight_layout()\n",
    "    exp.show_in_notebook()\n",
    "    return(j,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(features)\\nwith plt.style.context(\"ggplot\"):\\n    fig = plt.figure(figsize=(8,6))\\n    plt.barh(range(len(mo.coef_[0])), mo.coef_[0], color=[\"red\" if coef<0 else \"green\" for coef in mo.coef_[0]])\\n    plt.yticks(range(len(mo.coef_[0])), features);\\n    plt.title(\"Weights\")\\n    '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(features)\n",
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.barh(range(len(mo.coef_[0])), mo.coef_[0], color=[\"red\" if coef<0 else \"green\" for coef in mo.coef_[0]])\n",
    "    plt.yticks(range(len(mo.coef_[0])), features);\n",
    "    plt.title(\"Weights\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def limenaivebayes(nbfake,nbtrue):\\n    data,lenfake,lentrue=preprocessing()\\n    \\n    x1=dataproc(data,nbfake,nbtrue,lenfake,lentrue)\\n    X_train=x1[0]\\n    X_test=x1[1]\\n    y_train=x1[2]\\n    y_test=x1[3]\\n    vtrain,vtest,vectorizer,features=vecto(X_train,X_test)\\n    #classifNaiveBayes(vtrain,y_train,vectorizer,X_test,features)\\n    j,exp=classifNaiveBayes(vtrain,y_train,vectorizer,X_test,features)\\n    #print(\\'Texte classé = \\',X_test[j])\\n\\n    outputs = open(\"outputs.txt\", \"w\")\\n    outputs.write(\"Texte classé = \")\\n    outputs.write(X_test[j])\\n    #outputs.write(exp)\\n    outputs.write(\"/n\")\\n    outputs.close()\\n    \\nlimenaivebayes(5,5)\\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def limenaivebayes(nbfake,nbtrue):\n",
    "    data,lenfake,lentrue=preprocessing()\n",
    "    \n",
    "    x1=dataproc(data,nbfake,nbtrue,lenfake,lentrue)\n",
    "    X_train=x1[0]\n",
    "    X_test=x1[1]\n",
    "    y_train=x1[2]\n",
    "    y_test=x1[3]\n",
    "    vtrain,vtest,vectorizer,features=vecto(X_train,X_test)\n",
    "    #classifNaiveBayes(vtrain,y_train,vectorizer,X_test,features)\n",
    "    j,exp=classifNaiveBayes(vtrain,y_train,vectorizer,X_test,features)\n",
    "    #print('Texte classé = ',X_test[j])\n",
    "\n",
    "    outputs = open(\"outputs.txt\", \"w\")\n",
    "    outputs.write(\"Texte classé = \")\n",
    "    outputs.write(X_test[j])\n",
    "    #outputs.write(exp)\n",
    "    outputs.write(\"/n\")\n",
    "    outputs.close()\n",
    "    \n",
    "limenaivebayes(5,5)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train =  8760     reuters scores photographers 2016 us president...\n",
      "0        washington reuters head conservative republica...\n",
      "34798    buenos aires reuters argentina given rescuing ...\n",
      "2        washington reuters special counsel investigati...\n",
      "39108    ankara reuters turkey president tayyip erdogan...\n",
      "1        washington reuters transgender people allowed ...\n",
      "3        washington reuters trump campaign adviser geor...\n",
      "12145    united nationsyangon reuters us secretary stat...\n",
      "Name: text, dtype: object\n",
      "data =  8760     reuters scores photographers 2016 us president...\n",
      "0        washington reuters head conservative republica...\n",
      "34798    buenos aires reuters argentina given rescuing ...\n",
      "2        washington reuters special counsel investigati...\n",
      "39108    ankara reuters turkey president tayyip erdogan...\n",
      "Name: text, dtype: object\n",
      "sentitrain =  [[1.005  1.878  1.118  1.9805]\n",
      " [1.064  1.813  1.123  1.9801]\n",
      " [1.052  1.833  1.114  1.886 ]\n",
      " [1.072  1.844  1.084  1.3947]\n",
      " [1.244  1.652  1.104  0.2421]\n",
      " [1.09   1.768  1.142  1.9265]\n",
      " [1.089  1.816  1.095  1.128 ]\n",
      " [1.169  1.673  1.159  0.1595]]\n",
      "sentitest =  [[1.153  1.782  1.065  0.3631]\n",
      " [1.076  1.802  1.123  1.9687]]\n",
      "o= [0.02598498 0.         0.         ... 0.         0.         0.        ]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/evan/EMSCC-FakeNewsProject/sentimentanalysis.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/EMSCC-FakeNewsProject/sentimentanalysis.ipynb#ch0000009?line=74'>75</a>\u001b[0m explainer \u001b[39m=\u001b[39m lime_tabular\u001b[39m.\u001b[39mLimeTabularExplainer(sentitrain,mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m,categorical_features\u001b[39m=\u001b[39mfeatures,feature_names\u001b[39m=\u001b[39mfeatures)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/EMSCC-FakeNewsProject/sentimentanalysis.ipynb#ch0000009?line=75'>76</a>\u001b[0m \u001b[39m# Utilisation de Lime sur le modèle entrainé\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/evan/EMSCC-FakeNewsProject/sentimentanalysis.ipynb#ch0000009?line=77'>78</a>\u001b[0m exp\u001b[39m=\u001b[39mexplainer\u001b[39m.\u001b[39;49mexplain_instance(data_row\u001b[39m=\u001b[39;49mo,predict_fn\u001b[39m=\u001b[39;49mmo\u001b[39m.\u001b[39;49mpredict_proba, num_features\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m) \u001b[39m#labels=features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/EMSCC-FakeNewsProject/sentimentanalysis.ipynb#ch0000009?line=78'>79</a>\u001b[0m \u001b[39m# Explication de la classification d'une news par les mots ayant eu le plus de poids dans sa classification par le modèle\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/EMSCC-FakeNewsProject/sentimentanalysis.ipynb#ch0000009?line=79'>80</a>\u001b[0m exp\u001b[39m.\u001b[39mas_pyplot_figure()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py:346\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor, sampling_method)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=342'>343</a>\u001b[0m \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39missparse(data_row) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39misspmatrix_csr(data_row):\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=343'>344</a>\u001b[0m     \u001b[39m# Preventative code: if sparse, convert to csr format if not in csr format already\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=344'>345</a>\u001b[0m     data_row \u001b[39m=\u001b[39m data_row\u001b[39m.\u001b[39mtocsr()\n\u001b[0;32m--> <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=345'>346</a>\u001b[0m data, inverse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__data_inverse(data_row, num_samples, sampling_method)\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=346'>347</a>\u001b[0m \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39missparse(data):\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=347'>348</a>\u001b[0m     \u001b[39m# Note in sparse case we don't subtract mean since data would become dense\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=348'>349</a>\u001b[0m     scaled_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale_)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py:566\u001b[0m, in \u001b[0;36mLimeTabularExplainer.__data_inverse\u001b[0;34m(self, data_row, num_samples, sampling_method)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=563'>564</a>\u001b[0m inverse \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=564'>565</a>\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m categorical_features:\n\u001b[0;32m--> <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=565'>566</a>\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_values[column]\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=566'>567</a>\u001b[0m     freqs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_frequencies[column]\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=567'>568</a>\u001b[0m     inverse_column \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state\u001b[39m.\u001b[39mchoice(values, size\u001b[39m=\u001b[39mnum_samples,\n\u001b[1;32m    <a href='file:///Users/evan/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/lime/lime_tabular.py?line=568'>569</a>\u001b[0m                                               replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, p\u001b[39m=\u001b[39mfreqs)\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "#data=preprocessing()\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# Outil permettant d'extraire d'un texte le sentiment dominant (positif, négatif, neutre)\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "\n",
    "print(\"X_train = \",X_train)\n",
    "print('data = ',X_train[0:5])\n",
    "NEG=[]\n",
    "NEU=[]\n",
    "POS=[]\n",
    "COM=[]\n",
    "\n",
    "for news in X_train:\n",
    "    neg=analyzer.polarity_scores(news)['neg']\n",
    "    neu=analyzer.polarity_scores(news)['neu'] \n",
    "    pos=analyzer.polarity_scores(news)['pos']\n",
    "    com=analyzer.polarity_scores(news)['compound']\n",
    "    NEG=NEG+[neg]\n",
    "    NEU=NEU+[neu]\n",
    "    POS=POS+[pos]\n",
    "    COM=COM+[com]\n",
    "    \n",
    "A=NEG,NEU,POS,COM\n",
    "sentitrain=np.array(A)\n",
    "sentitrain=np.transpose(sentitrain)\n",
    "sentitrain=sentitrain+1 #MultinomialNB ne prend que des matrices X>0 \n",
    "print('sentitrain = ',sentitrain)\n",
    "\n",
    "\n",
    "NEG=[]\n",
    "NEU=[]\n",
    "POS=[]\n",
    "COM=[]\n",
    "for news in X_test:\n",
    "    neg=analyzer.polarity_scores(news)['neg']\n",
    "    neu=analyzer.polarity_scores(news)['neu'] \n",
    "    pos=analyzer.polarity_scores(news)['pos']\n",
    "    com=analyzer.polarity_scores(news)['compound']\n",
    "    NEG=NEG+[neg]\n",
    "    NEU=NEU+[neu]\n",
    "    POS=POS+[pos]\n",
    "    COM=COM+[com]\n",
    "\n",
    "sentitest=NEG,NEU,POS,COM\n",
    "sentitest=np.array(sentitest)\n",
    "sentitest=np.transpose(sentitest)\n",
    "sentitest=sentitest+1 #MultinomialNB ne prend que des matrices X>0\n",
    "print('sentitest = ',sentitest)\n",
    "\n",
    "\n",
    "'''\n",
    "positive sentiment: compound score >= 0.05\n",
    "neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "negative sentiment: compound score <= -0.05\n",
    "'''\n",
    "\n",
    "mo=MultinomialNB()\n",
    "mo.fit(sentitrain,y_train)\n",
    "\n",
    "i=X_test.index\n",
    "j=i[1]\n",
    "\n",
    "o=pd.Series(X_test[j])\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "vectorizer = vectorizer.fit(pd.concat([X_train,X_test]))\n",
    "\n",
    "o=vectorizer.transform(o)\n",
    "o=scipy.sparse.csr_matrix.toarray(o) # transformation de l'objet csr_matrix en numpy array, type d'entree de Lime\n",
    "o=o[0]\n",
    "\n",
    "features={neg,neu,pos,com}\n",
    "print(\"o=\",o)\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(sentitrain,mode=\"classification\",categorical_features=features,feature_names=features)\n",
    "# Utilisation de Lime sur le modèle entrainé\n",
    "\n",
    "exp=explainer.explain_instance(data_row=o,predict_fn=mo.predict_proba, num_features=20) #labels=features\n",
    "# Explication de la classification d'une news par les mots ayant eu le plus de poids dans sa classification par le modèle\n",
    "exp.as_pyplot_figure()\n",
    "from matplotlib import pyplot as plt\n",
    "plt.tight_layout()\n",
    "exp.show_in_notebook()\n",
    "# Fonction permettant de montrer l'interprétation de Lime sur la classification d'une news\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52fd7cfe315652c26f116941759022c1154f5724bf85b7c7e9d121c272da0755"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
